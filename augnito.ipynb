{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7045630,"sourceType":"datasetVersion","datasetId":4054274}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport transformers\nprint(transformers.__version__)\nfrom transformers.utils import send_example_telemetry\nfrom transformers import TrainingArguments, Trainer, default_data_collator\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, AutoConfig\nfrom datasets import load_dataset, load_metric\nfrom datasets import ClassLabel, Sequence\nfrom sklearn.metrics import accuracy_score, f1_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-09T13:17:06.896972Z","iopub.execute_input":"2024-01-09T13:17:06.897384Z","iopub.status.idle":"2024-01-09T13:17:14.830047Z","shell.execute_reply.started":"2024-01-09T13:17:06.897350Z","shell.execute_reply":"2024-01-09T13:17:14.828762Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"4.36.0\n","output_type":"stream"}]},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/nlp-mental-health-conversations/train.csv')\ndata=data.dropna()\nn=len(data)\nprint(n)\nN=list(range(n))\nrandom.shuffle(N)\ndata=data.iloc[N][0:1000].reset_index(drop=True)\ndisplay(data)\nprint(data.columns.tolist())\nprint('context')\nprint(data.iloc[0,0])\nprint()\nprint('response')\nprint(data.iloc[0,1])","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:17:20.868355Z","iopub.execute_input":"2024-01-09T13:17:20.869220Z","iopub.status.idle":"2024-01-09T13:17:20.990654Z","shell.execute_reply.started":"2024-01-09T13:17:20.869172Z","shell.execute_reply":"2024-01-09T13:17:20.989596Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"3508\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                               Context  \\\n0    I feel that I need to end my present relations...   \n1    I recently lost a friend to suicide.  I'm smok...   \n2    My depression has been reoccurring for a long ...   \n3    I am a really shy person. I'm currently in a g...   \n4    My husband and I have been together for seven ...   \n..                                                 ...   \n995  I believe it is wrong for men to look at inapp...   \n996  I crossdress and like to be feminine but I am ...   \n997  My spouse decided he no longer wanted me six y...   \n998  I'm obsessing about a terrible breakup. Everyt...   \n999  I am so angry. I feel like the arguments with ...   \n\n                                              Response  \n0    It sounds like you have some insight into the ...  \n1    Suicide is not a natural way to pass from this...  \n2    I couldn't help but notice that you did not sp...  \n3    Have you tried rehearsing to yourself or a tru...  \n4    Hi Texas, Thanks for your honesty; it helps me...  \n..                                                 ...  \n995  In my book, this is a boundary issue. Although...  \n996  Your happiness and healthiness is key.  I woul...  \n997  What a burden for you!Your husband cannot seem...  \n998  The best way to move on is to give yourself su...  \n999  I'm sorry you have so many arguments with your...  \n\n[1000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Context</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I feel that I need to end my present relations...</td>\n      <td>It sounds like you have some insight into the ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I recently lost a friend to suicide.  I'm smok...</td>\n      <td>Suicide is not a natural way to pass from this...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>My depression has been reoccurring for a long ...</td>\n      <td>I couldn't help but notice that you did not sp...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I am a really shy person. I'm currently in a g...</td>\n      <td>Have you tried rehearsing to yourself or a tru...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>My husband and I have been together for seven ...</td>\n      <td>Hi Texas, Thanks for your honesty; it helps me...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>I believe it is wrong for men to look at inapp...</td>\n      <td>In my book, this is a boundary issue. Although...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>I crossdress and like to be feminine but I am ...</td>\n      <td>Your happiness and healthiness is key.  I woul...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>My spouse decided he no longer wanted me six y...</td>\n      <td>What a burden for you!Your husband cannot seem...</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>I'm obsessing about a terrible breakup. Everyt...</td>\n      <td>The best way to move on is to give yourself su...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>I am so angry. I feel like the arguments with ...</td>\n      <td>I'm sorry you have so many arguments with your...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 2 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"['Context', 'Response']\ncontext\nI feel that I need to end my present relationship. He lives three hours away and likes the reassurance of having someone to talk to multiple times per day and seeing me once or twice a month. I want someone who is more present and more of a life companion. Lately, he has had a very busy work schedule and I have only seen him a few times in the last 6 weeks. I told him that I can't continue in this way because I constantly feel frustrated and angry and that he is not making the relationship enough of a priority. I also feel it is keeping me from possibly finding the relationship I want. We have been together 7 years. The problem is that I panic and experience anxiety and depression thinking of him with someone else and then thinking I will never meet someone I like. We have gone through this cycle already 4-5 times and I feel it is unhealthy to stay in it, but my aversion to the anxiety and depression I experience upon separation always leads me to reconcile.\n\nresponse\nIt sounds like you have some insight into the cycle that you describe with your current relationship and at the same time you are still feeling stuck. It also sounds like the distressing feelings that you experience, when you imagine what will happen for you and your current partner, are pretty overwhelming. A competent therapist may be able to help you work through these difficult thoughts and feelings and find a resolution to this cycle that will feel right to you.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:17:24.288818Z","iopub.execute_input":"2024-01-09T13:17:24.289287Z","iopub.status.idle":"2024-01-09T13:17:36.178074Z","shell.execute_reply.started":"2024-01-09T13:17:24.289249Z","shell.execute_reply":"2024-01-09T13:17:36.176607Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:17:36.180367Z","iopub.execute_input":"2024-01-09T13:17:36.180754Z","iopub.status.idle":"2024-01-09T13:17:36.186914Z","shell.execute_reply.started":"2024-01-09T13:17:36.180718Z","shell.execute_reply":"2024-01-09T13:17:36.185757Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:17:36.188233Z","iopub.execute_input":"2024-01-09T13:17:36.189136Z","iopub.status.idle":"2024-01-09T13:17:36.200554Z","shell.execute_reply.started":"2024-01-09T13:17:36.189091Z","shell.execute_reply":"2024-01-09T13:17:36.199334Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class CustomModel(AutoModelForCausalLM):\n    def __init__(self, config):\n        super().__init__(config)\n        self.max_input_length = 514\n        self.config.max_position_embeddings = self.max_input_length  # Align for consistency\n\n    def forward(self, **inputs):\n        input_ids = inputs.get(\"input_ids\")\n        if input_ids is not None and input_ids.size(1) > self.max_input_length:\n            input_ids = input_ids[:, :self.max_input_length]\n\n        # Debug information\n        print(\"Input_ids size:\", input_ids.size())\n        print(\"Attention_mask size:\", inputs.get(\"attention_mask\").size() if \"attention_mask\" in inputs else None)\n\n        return super().forward(**inputs)\n\n# Load model and tokenizer\nmodel_name = \"roberta-base\"\nconfig = AutoConfig.from_pretrained(model_name)\nmodel = CustomModel.from_pretrained(model_name, config=config)  # Pass adjusted config\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:17:36.202518Z","iopub.execute_input":"2024-01-09T13:17:36.202874Z","iopub.status.idle":"2024-01-09T13:17:38.737655Z","shell.execute_reply.started":"2024-01-09T13:17:36.202846Z","shell.execute_reply":"2024-01-09T13:17:38.736475Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_df(dataframe, tokenizer, max_sequence_length=512):\n    formatted_data = []\n    \n    for _, row in dataframe.iterrows():\n        input_text = f\"{row['Context']} \"\n        \n        if len(input_text) > max_sequence_length:\n            input_text = input_text[:max_sequence_length]\n\n        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=max_sequence_length, truncation=True)    \n \n        if 'Response' in row:\n            answer_text = row['Response']\n            answer_tokens = tokenizer(answer_text, return_tensors=\"pt\")[\"input_ids\"] \n        else:\n            answer_text, answer_tokens = None, None\n\n        formatted_data.append({\n            'input_ids': inputs['input_ids'],\n            'attention_mask': inputs['attention_mask'],\n            #'labels': answer_tokens,\n        })\n\n    return formatted_data","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:18:30.040477Z","iopub.execute_input":"2024-01-09T13:18:30.040929Z","iopub.status.idle":"2024-01-09T13:18:30.051715Z","shell.execute_reply.started":"2024-01-09T13:18:30.040892Z","shell.execute_reply":"2024-01-09T13:18:30.050423Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"formatted_df = format_df(data, tokenizer)\nprint(formatted_df[0])","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:18:30.975844Z","iopub.execute_input":"2024-01-09T13:18:30.976300Z","iopub.status.idle":"2024-01-09T13:18:32.467297Z","shell.execute_reply.started":"2024-01-09T13:18:30.976263Z","shell.execute_reply":"2024-01-09T13:18:32.466087Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"{'input_ids': tensor([[    0,   100,   619,    14,    38,   240,     7,   253,   127,  1455,\n          1291,     4,    91,  1074,   130,   722,   409,     8,  3829,     5,\n         13057, 12590,     9,   519,   951,     7,  1067,     7,  1533,   498,\n           228,   183,     8,  1782,   162,   683,    50,  2330,    10,   353,\n             4,    38,   236,   951,    54,    16,    55,  1455,     8,    55,\n             9,    10,   301, 15625,     4,   226,  7223,     6,    37,    34,\n            56,    10,   182,  3610,   173,  3078,     8,    38,    33,   129,\n           450,   123,    10,   367,   498,    11,     5,    94,   231,   688,\n             4,    38,   174,   123,    14,    38,    64,    75,   535,    11,\n            42,   169,   142,    38,  5861,   619,  8164,     8,  5800,     8,\n            14,    37,    16,    45,   442,     5,  1291,   615,     9,    10,\n          2052,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, formatted_data):\n        self.formatted_data = formatted_data\n\n    def __len__(self):\n        return len(self.formatted_data)\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': self.formatted_data[idx]['input_ids'].squeeze(),\n            'attention_mask': self.formatted_data[idx]['attention_mask'].squeeze(), \n            #'labels': self.formatted_data[idx]['labels'].squeeze() if self.formatted_data[idx]['labels'] is not None else None,\n            'start_positions': self.formatted_data[idx]['start_positions'] if 'start_positions' in self.formatted_data[idx] else None,\n            'end_positions': self.formatted_data[idx]['end_positions'] if 'end_positions' in self.formatted_data[idx] else None\n        }\n    \nn=len(formatted_df)\ntrainset = CustomDataset(formatted_df[0:n*4//5])\ntestset = CustomDataset(formatted_df[n*4//5:])","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:18:33.229750Z","iopub.execute_input":"2024-01-09T13:18:33.230191Z","iopub.status.idle":"2024-01-09T13:18:33.238568Z","shell.execute_reply.started":"2024-01-09T13:18:33.230156Z","shell.execute_reply":"2024-01-09T13:18:33.237259Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\n\ndef custom_collate_fn(batch):\n    input_ids = pad_sequence([item['input_ids'] for item in batch], batch_first=True)\n    attention_mask = pad_sequence([item['attention_mask'] for item in batch], batch_first=True)\n\n    #labels = pad_sequence([item['labels'] for item in batch if item['labels'] is not None], batch_first=True) if any(item['labels'] is not None for item in batch) else None\n\n    return {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask,\n        #'labels': labels,\n    }\n        \nbatch_size = 8  \n\ntrain_dataloader = DataLoader(trainset, batch_size=batch_size, \n                              shuffle=True, collate_fn=custom_collate_fn)\ntest_dataloader = DataLoader(testset, batch_size=batch_size, \n                              shuffle=False, collate_fn=custom_collate_fn)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:18:33.518880Z","iopub.execute_input":"2024-01-09T13:18:33.519312Z","iopub.status.idle":"2024-01-09T13:18:33.527807Z","shell.execute_reply.started":"2024-01-09T13:18:33.519280Z","shell.execute_reply":"2024-01-09T13:18:33.526376Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \nmodel.to(device)\nmodel.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:18:34.479683Z","iopub.execute_input":"2024-01-09T13:18:34.480143Z","iopub.status.idle":"2024-01-09T13:18:34.495040Z","shell.execute_reply.started":"2024-01-09T13:18:34.480105Z","shell.execute_reply":"2024-01-09T13:18:34.493725Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"RobertaForCausalLM(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (lm_head): RobertaLMHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for batch in train_dataloader:\n    input_ids = batch['input_ids'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    #labels = batch['labels'].to(device) if batch['labels'] is not None else None\n\n    outputs = model(input_ids=input_ids, attention_mask=attention_mask,)# labels=labels","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:18:34.833898Z","iopub.execute_input":"2024-01-09T13:18:34.834306Z","iopub.status.idle":"2024-01-09T13:21:43.321011Z","shell.execute_reply.started":"2024-01-09T13:18:34.834276Z","shell.execute_reply":"2024-01-09T13:21:43.319752Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.eval()\nall_predictions = []\n\nwith torch.no_grad():\n    for batch in test_dataloader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n\n        # Forward pass\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        \n        # Get the predicted token IDs\n        logits = outputs.logits\n        predicted_ids = torch.argmax(logits, dim=-1)\n\n        # Convert token IDs to tokens\n        predicted_tokens = tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)\n\n        # Extend the list of predictions\n        all_predictions.extend(predicted_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:21:43.322979Z","iopub.execute_input":"2024-01-09T13:21:43.323583Z","iopub.status.idle":"2024-01-09T13:22:32.473453Z","shell.execute_reply.started":"2024-01-09T13:21:43.323550Z","shell.execute_reply":"2024-01-09T13:22:32.472037Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}